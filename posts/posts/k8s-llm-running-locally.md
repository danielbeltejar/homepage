Configur√© un cl√∫ster Kubernetes optimizado para IA acelerada por GPU. Instal√© el plugin de dispositivo NVIDIA, cre√© una RuntimeClass personalizada y desplegu√© DeepSeek-R1 con ollama, como API LLM local.  

## Pasos  
1. **Instalar `nvidia-container-toolkit`**  
   Utilic√© `dnf` en Red Hat para instalar las herramientas necesarias.  

2. **Plugin NVIDIA**  
   Instal√© el plugin en Kubernetes para habilitar GPUs y asignarlas a tareas espec√≠ficas.  

3. **RuntimeClass NVIDIA**  
   Cre√© una clase personalizada para garantizar que los pods con requisitos de GPU se programen en nodos compatibles.  

4. **Despliegue de DeepSeek-R1**  
   Desplegu√© DeepSeek-R1 como API local, accediendo al modelo sin depender de servicios externos.  

## üõ†Ô∏è Hardware del nodo de Kubernetes 
- **RAM**: 64GB DDR5 (DDR5 ideal por su ancho de banda por si tu GPU no tiene suficiente VRAM).  
- **CPU**: Intel i9-13900. (Los prompts utilizan un core aun utilizando GPU)
- **GPU**: NVIDIA RTX 3060 (12GB VRAM, donde se encontrara cargado el LLM).  

Con esta configuraci√≥n, DeepSeek-R1 genera **40 tokens/s**, manteniendo un rendimiento fluido.  

## ü§ë Ventajas Locales  
- Sin costes de APIs externas.  
- Respuestas r√°pidas gracias a la GPU.  
- Uso ilimitado con resultados consistentes.  
